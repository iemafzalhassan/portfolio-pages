<!doctype html><html lang=en-us dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en-us"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>Running Llama 3.2 Locally with OpenWebUI and Docker &#183; Afzal Hassan - DevOps Engineer</title><meta name=title content="Running Llama 3.2 Locally with OpenWebUI and Docker &#183; Afzal Hassan - DevOps Engineer"><meta name=description content="Complete guide to set up Llama 3.2 AI model locally with OpenWebUI using Docker for privacy-focused AI interactions"><meta name=keywords content="AI,Llama,Docker,OpenWebUI,DevOps,Privacy,Local AI,"><link rel=canonical href=https://iemafzalhassan.me/portfolio-pages/blogs/ollama/><link type=text/css rel=stylesheet href=/portfolio-pages/css/main.bundle.min.cf17ddb1e5d433023c5e3eccaf953d75fc74d1138baf3b0124046927e804188fd7fe33e9e5754adbd342da307e5c85a9de788a2d73f554c1d916bc3887e2acf4.css integrity="sha512-zxfdseXUMwI8Xj7Mr5U9dfx00ROLrzsBJARpJ+gEGI/X/jPp5XVK29NC2jB+XIWp3niKLXP1VMHZFrw4h+Ks9A=="><script type=text/javascript src=/portfolio-pages/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/portfolio-pages/js/main.bundle.min.a187118b41a60744310065c567365de85730c8495301d0ebae41810cc6f7a47432b1de7d4f3b11338959f1ac50c266be6b4b73acf6bf770016eb59b602cc1aa0.js integrity="sha512-oYcRi0GmB0QxAGXFZzZd6FcwyElTAdDrrkGBDMb3pHQysd59TzsRM4lZ8axQwma+a0tzrPa/dwAW61m2AswaoA==" data-copy=Copy data-copied=Copied></script><script src=/portfolio-pages/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><link rel=apple-touch-icon sizes=180x180 href=/portfolio-pages/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/portfolio-pages/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/portfolio-pages/favicon-16x16.png><link rel=manifest href=/portfolio-pages/site.webmanifest><meta property="og:url" content="https://iemafzalhassan.me/portfolio-pages/blogs/ollama/"><meta property="og:site_name" content="Afzal Hassan - DevOps Engineer"><meta property="og:title" content="Running Llama 3.2 Locally with OpenWebUI and Docker"><meta property="og:description" content="Complete guide to set up Llama 3.2 AI model locally with OpenWebUI using Docker for privacy-focused AI interactions"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2024-11-11T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-11T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="Llama"><meta property="article:tag" content="Docker"><meta property="article:tag" content="OpenWebUI"><meta property="article:tag" content="DevOps"><meta property="article:tag" content="Privacy"><meta name=twitter:card content="summary"><meta name=twitter:title content="Running Llama 3.2 Locally with OpenWebUI and Docker"><meta name=twitter:description content="Complete guide to set up Llama 3.2 AI model locally with OpenWebUI using Docker for privacy-focused AI interactions"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Blog Posts","name":"Running Llama 3.2 Locally with OpenWebUI and Docker","headline":"Running Llama 3.2 Locally with OpenWebUI and Docker","description":"Complete guide to set up Llama 3.2 AI model locally with OpenWebUI using Docker for privacy-focused AI interactions","abstract":"\u003cp\u003eIf you\u0026rsquo;ve ever wanted to run a powerful AI language model like Llama 3.2 on your own computer—without worrying about sharing your data with companies or relying on cloud services—this guide will walk you through the entire process. We\u0026rsquo;ll cover how to download, install, and set up \u003cstrong\u003eOpenWebUI\u003c\/strong\u003e on your local machine using \u003cstrong\u003eDocker\u003c\/strong\u003e and integrate it with a locally installed \u003cstrong\u003eLlama 3.2 model\u003c\/strong\u003e.\u003c\/p\u003e\n\u003chr\u003e\n\n\u003ch3 class=\u0022relative group\u0022\u003eWhat You Will Need: \n    \u003cdiv id=\u0022what-you-will-need\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline\u0022 href=\u0022#what-you-will-need\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eA computer with at least 8GB of RAM\u003c\/strong\u003e (for smooth performance with the Llama models).\u003c\/li\u003e\n\u003cli\u003e\u003cstrong\u003eDocker\u003c\/strong\u003e installed on your computer.\u003c\/li\u003e\n\u003cli\u003e\u003cstrong\u003eA terminal\u003c\/strong\u003e for running commands.\u003c\/li\u003e\n\u003cli\u003e\u003cstrong\u003eA bit of patience\u003c\/strong\u003e as the installation process will take some time.\u003c\/li\u003e\n\u003c\/ol\u003e\n\u003chr\u003e\n\n\u003ch3 class=\u0022relative group\u0022\u003eStep 1: Download and Install \u003cstrong\u003eOllama\u003c\/strong\u003e (LLama Model Assistant) \n    \u003cdiv id=\u0022step-1-download-and-install-ollama-llama-model-assistant\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline\u0022 href=\u0022#step-1-download-and-install-ollama-llama-model-assistant\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h3\u003e\n\u003cp\u003eFirst, we need to install \u003cstrong\u003eOllama\u003c\/strong\u003e, a tool that allows you to manage and run local AI models such as \u003cstrong\u003eLlama 3.2\u003c\/strong\u003e.\u003c\/p\u003e","inLanguage":"en-us","url":"https:\/\/iemafzalhassan.me\/portfolio-pages\/blogs\/ollama\/","author":{"@type":"Person","name":"Afzal Hassan"},"copyrightYear":"2024","dateCreated":"2024-11-11T00:00:00\u002b00:00","datePublished":"2024-11-11T00:00:00\u002b00:00","dateModified":"2024-11-11T00:00:00\u002b00:00","keywords":["AI","Llama","Docker","OpenWebUI","DevOps","Privacy","Local AI"],"mainEntityOfPage":"true","wordCount":"1223"}]</script><meta name=author content="Afzal Hassan"><link href=GitHub rel=me><link href=https://github.com/iemafzalhassan rel=me><link href=LinkedIn rel=me><link href=https://www.linkedin.com/in/iemafzalhassan/ rel=me><link href=Twitter rel=me><link href=https://x.com/iemafzalhassan rel=me><script src=/portfolio-pages/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>
Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px] z-100"><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3 pt-[2px] pr-0 pb-[3px] pl-0"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/portfolio-pages/ class="text-base font-medium text-gray-500 hover:text-gray-900">Afzal Hassan - DevOps Engineer</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/portfolio-pages/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Home</p></a><a href=/portfolio-pages/blogs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Posts</p></a><a href=/portfolio-pages/projects/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Projects</p></a><a href=/portfolio-pages/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><div id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50 pt-[5px]"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/portfolio-pages/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Home</p></a></li><li class=mt-1><a href=/portfolio-pages/blogs/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Posts</p></a></li><li class=mt-1><a href=/portfolio-pages/projects/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Projects</p></a></li><li class=mt-1><a href=/portfolio-pages/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li></ul></div></div></div></div></div></div><script type=text/javascript src=/portfolio-pages/js/background-blur.min.0ad33cb9c066f652728b2cc09c9ceaf32645544f48e8b6b38f120d86f433ed997da275a49e6151fe0176430c45376812708d84727f3f969101fb44a4345b3f34.js integrity="sha512-CtM8ucBm9lJyiyzAnJzq8yZFVE9I6LazjxINhvQz7Zl9onWknmFR/gF2QwxFN2gScI2Ecn8/lpEB+0SkNFs/NA==" data-target-id=menu-blur></script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Running Llama 3.2 Locally with OpenWebUI and Docker</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-11-11T00:00:00+00:00>November 11, 2024</time><span class="px-2 text-primary-500">&#183;</span><span>1223 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">6 mins</span></div></div><div class="flex author"><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Afzal Hassan</div><div class="text-sm text-neutral-700 dark:text-neutral-400">DevOps Engineer & Cloud Enthusiast</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=GitHub target=_blank aria-label=Name rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/iemafzalhassan target=_blank aria-label=Url rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=LinkedIn target=_blank aria-label=Name rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://www.linkedin.com/in/iemafzalhassan/ target=_blank aria-label=Url rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=Twitter target=_blank aria-label=Name rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a>
<a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/iemafzalhassan target=_blank aria-label=Url rel="me noopener noreferrer"><span class="inline-block align-text-bottom"></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p>If you&rsquo;ve ever wanted to run a powerful AI language model like Llama 3.2 on your own computer—without worrying about sharing your data with companies or relying on cloud services—this guide will walk you through the entire process. We&rsquo;ll cover how to download, install, and set up <strong>OpenWebUI</strong> on your local machine using <strong>Docker</strong> and integrate it with a locally installed <strong>Llama 3.2 model</strong>.</p><hr><h3 class="relative group">What You Will Need:<div id=what-you-will-need class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#what-you-will-need aria-label=Anchor>#</a></span></h3><ol><li><strong>A computer with at least 8GB of RAM</strong> (for smooth performance with the Llama models).</li><li><strong>Docker</strong> installed on your computer.</li><li><strong>A terminal</strong> for running commands.</li><li><strong>A bit of patience</strong> as the installation process will take some time.</li></ol><hr><h3 class="relative group">Step 1: Download and Install <strong>Ollama</strong> (LLama Model Assistant)<div id=step-1-download-and-install-ollama-llama-model-assistant class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-1-download-and-install-ollama-llama-model-assistant aria-label=Anchor>#</a></span></h3><p>First, we need to install <strong>Ollama</strong>, a tool that allows you to manage and run local AI models such as <strong>Llama 3.2</strong>.</p><h3 class="relative group">To install Ollama:<div id=to-install-ollama class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#to-install-ollama aria-label=Anchor>#</a></span></h3><ol><li><strong>Go to the <a href=https://ollama.com/download target=_blank>Ollama website</a></strong> and download the appropriate version for your operating system.<ul><li>For <strong>Mac</strong>, download the <code>.dmg</code> file.</li><li>For <strong>Windows</strong>, download the <code>.exe</code> installer.</li><li>For <strong>Linux</strong>, <code>curl -fsSL https://ollama.com/install.sh | sh</code></li></ul></li><li><strong>Install Ollama</strong> by running the downloaded file and following the on-screen instructions.<ul><li>For <strong>Mac</strong>, move the Ollama application to your Applications folder.</li><li>For <strong>Windows</strong>, follow the prompts to install Ollama.</li></ul></li><li>Once the installation is complete, launch <strong>Ollama</strong>. You&rsquo;ll see a llama icon in your system tray (for Mac users, it will be in your Applications folder).</li></ol><hr><h3 class="relative group">Step 2: Install Llama 3.1 (as a Pre-requisite for Llama 3.2)<div id=step-2-install-llama-31-as-a-pre-requisite-for-llama-32 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-2-install-llama-31-as-a-pre-requisite-for-llama-32 aria-label=Anchor>#</a></span></h3><p>After Ollama is installed, you’ll first need to install <strong>Llama 3.1</strong> before installing the newer <strong>Llama 3.2</strong> model.</p><ol><li><strong>Open the terminal</strong> on your computer. You can open it on <strong>Mac</strong> from Applications > Utilities > Terminal, or on <strong>Windows</strong> by searching for <code>cmd</code> or <code>PowerShell</code>.</li><li>Copy the installation command provided by <strong>Ollama</strong> for <strong>Llama 3.1</strong> (you can find a prompt when you launch the app).</li><li>Paste the copied command into your terminal and press <strong>Enter</strong>. This will begin the installation of <strong>Llama 3.1</strong>.</li></ol><hr><h3 class="relative group">Step 3: Install <strong>Llama 3.2</strong><div id=step-3-install-llama-32 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-3-install-llama-32 aria-label=Anchor>#</a></span></h3><p>Now, we’ll install the latest version: <strong>Llama 3.2</strong>.</p><ol><li><p>Go back to the <strong>Ollama</strong> website and find the <strong>Llama 3.2</strong> model in the <strong>Models tab</strong>.</p></li><li><p>Copy the installation command for <strong>Llama 3.2</strong> from website Models tab or from below.</p><p><code>ollama run llama3.2-vision</code>
<code>ollama run llama3.2</code></p></li><li><p>Open your terminal and paste the command of the version you want to use.</p></li><li><p>Press <strong>Enter</strong> to begin the installation of <strong>Llama 3.2</strong>.</p></li></ol><hr><h3 class="relative group">Step 4: Install <strong>Docker</strong> (Containerization Tool)<div id=step-4-install-docker-containerization-tool class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-4-install-docker-containerization-tool aria-label=Anchor>#</a></span></h3><p>To run <strong>OpenWebUI</strong> on your local machine, you’ll need to install <strong>Docker</strong>. Docker is a platform that allows you to run applications in isolated containers, and it’s perfect for managing OpenWebUI.</p><h3 class="relative group">To install Docker:<div id=to-install-docker class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#to-install-docker aria-label=Anchor>#</a></span></h3><ol><li><strong>Go to the <a href=https://www.docker.com/products/docker-desktop/ target=_blank>Docker website</a></strong> and download the appropriate version for your operating system:<ul><li>For <a href=https://docs.docker.com/desktop/setup/install/windows-install/ target=_blank><strong>Windows</strong></a> and <a href=https://docs.docker.com/desktop/setup/install/mac-install/ target=_blank><strong>Mac</strong></a>, <a href=https://www.docker.com/products/docker-desktop/ target=_blank>Docker Desktop</a> is available.</li><li><a href=https://docs.docker.com/desktop/setup/install/linux/ target=_blank>For <strong>Linux</strong></a>, you can follow the specific installation instructions for your distribution.</li></ul></li><li><strong>Install Docker</strong> by running the downloaded installer and following the instructions.</li><li>Once Docker is installed, <strong>launch Docker</strong>. You should see the Docker icon appear in your system tray, indicating it’s running.</li></ol><hr><h3 class="relative group">Step 5: Run OpenWebUI with Docker (on Port 8080)<div id=step-5-run-openwebui-with-docker-on-port-8080 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-5-run-openwebui-with-docker-on-port-8080 aria-label=Anchor>#</a></span></h3><p>Now that you’ve got Docker installed, we’ll run <strong>OpenWebUI</strong> as a container and make it accessible on <strong>port 8080</strong> of your local machine.</p><p>GitHub Repo: <a href=https://github.com/iemafzalhassan/open-webui target=_blank>https://github.com/iemafzalhassan/open-webui</a></p><ol><li><p><strong>Open the terminal</strong> and run the following command to download and start the OpenWebUI container in detached mode (which means it will run in the background without blocking your terminal):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run -d -p 3000:8080 --add-host<span style=color:#f92672>=</span>host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</span></span></code></pre></div></li></ol><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 3.47.55 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/7e092e7e-4aa3-4aaa-9193-24b5a41daca4/Screenshot_2024-11-11_at_3.47.55_PM.png></figure></p><h3 class="relative group">Breakdown:<div id=breakdown class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#breakdown aria-label=Anchor>#</a></span></h3><ul><li><strong><code>docker run</code></strong>: Starts a new container from the specified image.</li><li><strong><code>-d</code></strong>: Run the container in detached mode (background).</li><li><strong><code>p 3000:8080</code></strong>: Map port <code>3000</code> on the host to port <code>8080</code> inside the container.</li><li><strong><code>-add-host=host.docker.internal:host-gateway</code></strong>: Add a host entry for the container to access the host machine using <code>host.docker.internal</code>.</li><li><strong><code>-v open-webui:/app/backend/data</code></strong>: Mount a volume named <code>open-webui</code> to the container’s <code>/app/backend/data</code> directory for persistent storage.</li><li><strong><code>-name open-webui</code></strong>: Assign the name <code>open-webui</code> to the container for easier reference.</li><li><strong><code>-restart always</code></strong>: Ensure the container restarts automatically if it crashes or if Docker restarts.</li><li><strong><code>ghcr.io/open-webui/open-webui:main</code></strong>: Use the <code>open-webui</code> image from GitHub Container Registry with the <code>main</code> tag (latest version).</li></ul><p>This command runs the container in the background, exposing the OpenWebUI interface on <code>http://localhost:3000</code>, while ensuring persistent data storage and automatic restarts.</p><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 4.18.47 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/498d98a7-88a4-42cc-a3b6-4db074500b7d/Screenshot_2024-11-11_at_4.18.47_PM.png></figure></p><ol><li>After running the command, Docker will automatically download the necessary image and start the OpenWebUI container in the background.</li></ol><hr><h3 class="relative group">Step 6: Access OpenWebUI on Localhost<div id=step-6-access-openwebui-on-localhost class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#step-6-access-openwebui-on-localhost aria-label=Anchor>#</a></span></h3><p>Now that the container is running, you can access OpenWebUI through your web browser.</p><ol><li><p><strong>Open your web browser</strong> (Chrome, Firefox, etc.) and go to:</p><pre tabindex=0><code>http://localhost:3000/
</code></pre></li></ol><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 4.01.13 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/8607948f-2510-4dd9-8de6-dcccc0b97968/Screenshot_2024-11-11_at_4.01.13_PM.png></figure></p><ol><li>This will bring up the OpenWebUI interface where you can select the Llama model you installed (e.g., <strong>Llama 3.2</strong>).</li></ol><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 4.01.24 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/a65dc5ed-3c74-4839-b58c-45095cfed367/Screenshot_2024-11-11_at_4.01.24_PM.png></figure></p><ol><li>You can now start interacting with Llama 3.2 directly in your browser, just like you would with ChatGPT or any other chatbot.</li></ol><hr><h3 class="relative group">Using OpenWebUI with Llama 3.2<div id=using-openwebui-with-llama-32 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#using-openwebui-with-llama-32 aria-label=Anchor>#</a></span></h3><p>Once you’ve got OpenWebUI running, you can select the Llama 3.2 model you installed and start typing prompts. The cool thing is that everything is running <strong>locally</strong>, meaning <strong>no data is sent to any third party</strong>. You can safely use the AI as much as you want without worrying about privacy.</p><h3 class="relative group">Example DevOps Prompts:<div id=example-devops-prompts class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#example-devops-prompts aria-label=Anchor>#</a></span></h3><ol><li><p><strong>Dockerfile Creation Assistance</strong>:</p><ul><li><p><strong>Example-Prompt</strong>: &ldquo;Can you help me create a Dockerfile for a Node.js application that installs dependencies, runs tests, and exposes port 8080?&rdquo;</p><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 4.11.15 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/57f59b81-e452-4401-8267-0b8f5f3ab8ae/Screenshot_2024-11-11_at_4.11.15_PM.png></figure></p><p><figure><img class="my-0 rounded-md" loading=lazy alt="Screenshot 2024-11-11 at 4.11.52 PM.png" src=https://prod-files-secure.s3.us-west-2.amazonaws.com/8b557715-1f08-43ae-ac1a-b814d80e7850/992fa6b8-c101-45ff-910c-ba7770862e6a/Screenshot_2024-11-11_at_4.11.52_PM.png></figure></p></li></ul></li><li><p><strong>Kubernetes Deployment Manifest</strong>:</p><ul><li><strong>Example-Prompt</strong>: &ldquo;Can you generate a Kubernetes deployment YAML for deploying a MySQL database with persistent storage?&rdquo;</li></ul></li><li><p><strong>Jenkins Groovy Script for CI/CD Pipeline</strong>:</p><ul><li><strong>Example-Prompt</strong>: &ldquo;Write a Jenkins pipeline script to build and deploy a Docker image for a Python web app using GitHub as the source code repository.&rdquo;</li></ul></li></ol><hr><h3 class="relative group">Real-World Use Case for DevOps Engineers<div id=real-world-use-case-for-devops-engineers class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#real-world-use-case-for-devops-engineers aria-label=Anchor>#</a></span></h3><p>Running <strong>Llama 3.2</strong> locally can be a <strong>game-changer</strong> for <strong>DevOps engineers</strong>. Here are a few practical scenarios where <strong>Llama</strong> can help:</p><h3 class="relative group">1. <strong>Automating Documentation</strong>:<div id=1-automating-documentation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#1-automating-documentation aria-label=Anchor>#</a></span></h3><ul><li>Generating documentation for infrastructure and systems is an often-repetitive task. Llama can help by automatically creating <strong>README files</strong>, <strong>setup guides</strong>, and even <strong>system architecture descriptions</strong>.</li></ul><h3 class="relative group">2. <strong>Troubleshooting and Debugging</strong>:<div id=2-troubleshooting-and-debugging class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#2-troubleshooting-and-debugging aria-label=Anchor>#</a></span></h3><ul><li>DevOps engineers often have to troubleshoot issues related to system performance or application failures. Llama can quickly answer common <strong>troubleshooting queries</strong>, help <strong>parse logs</strong>, and suggest <strong>solutions</strong> for common issues (like container crashes or networking errors).</li></ul><h3 class="relative group">3. <strong>Creating Infrastructure-as-Code</strong>:<div id=3-creating-infrastructure-as-code class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#3-creating-infrastructure-as-code aria-label=Anchor>#</a></span></h3><ul><li>With Llama, you can generate <strong>Terraform</strong> or <strong>CloudFormation</strong> templates for setting up cloud infrastructure, or automate the creation of <strong>Kubernetes manifests</strong> and <strong>Docker configurations</strong>—all using simple prompts.</li></ul><h3 class="relative group">4. <strong>Script Generation</strong>:<div id=4-script-generation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#4-script-generation aria-label=Anchor>#</a></span></h3><ul><li>Need a script to automate a task? Simply ask Llama to write a script in <strong>Python</strong>, <strong>Bash</strong>, or even <strong>PowerShell</strong>. Whether it&rsquo;s automating cloud infrastructure provisioning or batch processing logs, Llama is capable of understanding complex requests and generating working code.</li></ul><h3 class="relative group">5. <strong>Security & Privacy</strong>:<div id=5-security--privacy class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#5-security--privacy aria-label=Anchor>#</a></span></h3><ul><li>By running Llama locally, all your data stays <strong>on your machine</strong>. This is particularly valuable for DevOps engineers working with sensitive data who want to avoid sending telemetry or logs to third-party services.</li></ul><h3 class="relative group">6. <strong>Code Reviews</strong>:<div id=6-code-reviews class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href=#6-code-reviews aria-label=Anchor>#</a></span></h3><ul><li>Need to automate code review? Llama can assist in generating code review comments for various languages and frameworks, ensuring your code follows best practices and adheres to internal guidelines.</li></ul><p>The best part? This AI setup is <strong>free</strong>, doesn’t involve cloud services, and gives you full control over the data and model. You can use it as much as you want without incurring any costs or giving up privacy.</p><hr></div></div><script type=text/javascript src=/portfolio-pages/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA==" data-oid=views_blogs/ollama.md data-oid-likes=likes_blogs/ollama.md></script></section><footer class="pt-8 max-w-prose print:hidden"></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0 z-10"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Afzal Hassan</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/portfolio-pages/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500" data-url=https://iemafzalhassan.me/portfolio-pages/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>